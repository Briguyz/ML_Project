---
title: "Regression Tree and SVM Model"
author: "Brian"
date: "2022-11-22"
output: html_document
---

## Including Libraries
```{r, include=FALSE}
library(tidyverse)
library(readr)
library(caret)
library(ggplot2)
library(dplyr)
library(e1071)
library(tidyr)
library(knitr)
library(rpart)
library(rattle)
library(rpart.plot)
library(arules)
library(Metrics)

```

# Importing Data
```{r}
# Download Test and Training data
set.seed(3)
movie_test <- read_csv('movie_test.csv', trim_ws = TRUE)
movie_train <- read_csv('movie_train.csv', trim_ws = TRUE)
movie_dataset <- read_csv('movies_train_test.csv', trim_ws = TRUE)
```


# Training Data on Voter Count
```{r}
#Create tables for different models
VC.model_movie_train <- subset(movie_train, 
                            select = -c(revenue, vote_average))
#Voter Count on Training Data
vc1 <- rpart(
  formula = vote_count ~.,
  data    = VC.model_movie_train,
  )
vc1
fancyRpartPlot(vc1, main = "VOTE COUNT")

```

# Testing Voter Count model on Test Data 
```{r}
#Display the results
printcp(vc1)

#Visualize cross-validation results
plotcp(vc1)

#Summary of models:
#If no value comes from model, no impact towards the outcome. write in report
#Don't use profit as predictor

#Prune trees
pvc1 <- prune(vc1, cp = 0.023104) 
pvc2 <- prune(vc1, cp = 0.014096) 
pvc3 <- prune(vc1, cp = 0.010000) 



#Plot Pruned Tree
fancyRpartPlot(pvc1, 
               main = "VOTE COUNT", 
               sub = "cp = 0.023")
fancyRpartPlot(pvc2, 
               main = "VOTE COUNT", 
               sub = "cp = 0.014")
fancyRpartPlot(pvc3, 
               main = "VOTE COUNT", 
               sub = "cp = 0.010")


train.pred.vc1 <- predict(pvc1, movie_train)
train.pred.vc2 <- predict(pvc2, movie_train)
train.pred.vc3 <- predict(pvc3, movie_train)

test.pred.vc1 <- predict(pvc1, movie_test)
test.pred.vc2 <- predict(pvc2, movie_test)
test.pred.vc3 <- predict(pvc3, movie_test)

#On Actual Data                          
pred.vc1 <- predict(pvc1, movie_dataset)
pred.vc2 <- predict(pvc2, movie_dataset)
pred.vc3 <- predict(pvc3, movie_dataset)

#Training Data Accuracy
#Model 3 has the best Mean Absolute Error of 1451.318
MAE(movie_train$vote_count, train.pred.vc1)
MAE(movie_train$vote_count, train.pred.vc2)
MAE(movie_train$vote_count, train.pred.vc3)

#Model 3 has the best Root Mean Square Error of 2483.412
RMSE(movie_train$vote_count, train.pred.vc1)
RMSE(movie_train$vote_count, train.pred.vc2)
RMSE(movie_train$vote_count, train.pred.vc3)

#Model 2 has the best Relative Absolute Error of 0.84
rae(movie_train$vote_count, train.pred.vc1)
rae(movie_train$vote_count, train.pred.vc2)
rae(movie_train$vote_count, train.pred.vc3)

#Test Data Accuracy
#Model 3 has the best Mean Absolute Error of 1466.072
MAE(movie_test$vote_count, test.pred.vc1)
MAE(movie_test$vote_count, test.pred.vc2)
MAE(movie_test$vote_count, test.pred.vc3)

#Model 3 has the best Root Mean Square Error of 2510.368
RMSE(movie_test$vote_count, test.pred.vc1)
RMSE(movie_test$vote_count, test.pred.vc2)
RMSE(movie_test$vote_count, test.pred.vc3)

#Model 2 has the best Relative Absolute Error of 0.85
rae(movie_test$vote_count, test.pred.vc1)
rae(movie_test$vote_count, test.pred.vc2)
rae(movie_test$vote_count, test.pred.vc3)

#Actual Data Accuracy
#Model 3 has the best Mean Absolute Error of 1454.267
MAE(movie_dataset$vote_count, pred.vc1)
MAE(movie_dataset$vote_count, pred.vc2)
MAE(movie_dataset$vote_count, pred.vc3)

#Model 3 has the best Root Mean Square Error of 2488.822
RMSE(movie_dataset$vote_count, pred.vc1)
RMSE(movie_dataset$vote_count, pred.vc2)
RMSE(movie_dataset$vote_count, pred.vc3)

#Model 3 has the best Relative Absolute Error of 0.841
rae(movie_dataset$vote_count, pred.vc1)
rae(movie_dataset$vote_count, pred.vc2)
rae(movie_dataset$vote_count, pred.vc3)

#Use model 3
fancyRpartPlot(pvc3, 
               main = "VOTE COUNT", 
               sub = "")

```

